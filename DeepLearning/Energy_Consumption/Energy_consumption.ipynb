{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Bt3Jp31jJ6SB"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "br5Miqu2J_Og"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('predict_energy_consumption.xls')\n",
        "data.head()\n",
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6eFng-9Kesl",
        "outputId": "b810f36c-9e7d-4eb1-c0de-a440aa0450e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['temperature', 'humidity', 'wind_speed', 'solar_irradiance',\n",
              "       'energy_consumption'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = data[['temperature', 'humidity', 'wind_speed', 'solar_irradiance']].values\n",
        "y = data['energy_consumption'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "10AGaN_DOp0-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHZaxYP21gqJ",
        "outputId": "acb5fcf4-6fb8-493c-bab0-d9fc6aabcc5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer with 64 neurons\n",
        "    Dense(32, activation='relu'),  # Hidden layer with 32 neurons\n",
        "    Dense(1)  # Output layer for regression (1 neuron)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcgAGiol1ibX",
        "outputId": "0f07a181-8bc3-4be4-b66d-ca018ed7c134"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "# Mean Squared Error and Mean Absolute Error\n",
        "\n",
        "\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Mean Absolute Error: {test_mae:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9Iy7Js01jyE",
        "outputId": "a124e114-3f29-4465-8def-8d0a0defb8cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 92428.1953 - mae: 274.8015 - val_loss: 83666.7656 - val_mae: 258.9444\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 89588.0625 - mae: 269.5197 - val_loss: 83088.6094 - val_mae: 257.8231\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 89666.8438 - mae: 271.1635 - val_loss: 82221.4219 - val_mae: 256.1249\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 85847.8984 - mae: 263.7803 - val_loss: 80916.3906 - val_mae: 253.5470\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 85868.7344 - mae: 264.2358 - val_loss: 79002.7500 - val_mae: 249.7153\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 85374.2578 - mae: 262.6464 - val_loss: 76253.9219 - val_mae: 244.1064\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 84320.4375 - mae: 259.3355 - val_loss: 72491.5625 - val_mae: 236.2084\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 74736.4766 - mae: 240.5266 - val_loss: 67683.8047 - val_mae: 225.7034\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 73009.0078 - mae: 236.9061 - val_loss: 61812.4883 - val_mae: 212.2828\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 65350.0234 - mae: 219.1312 - val_loss: 55068.8867 - val_mae: 196.3530\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 60168.1523 - mae: 209.3230 - val_loss: 47754.6875 - val_mae: 179.2479\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46624.5195 - mae: 177.7889 - val_loss: 40513.5156 - val_mae: 162.7865\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39009.4570 - mae: 160.4836 - val_loss: 33642.4492 - val_mae: 146.8645\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35865.0938 - mae: 155.1069 - val_loss: 27878.6621 - val_mae: 133.6713\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28263.1992 - mae: 137.0308 - val_loss: 23569.9512 - val_mae: 124.1995\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24570.4902 - mae: 128.1257 - val_loss: 20715.1094 - val_mae: 119.2089\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20352.7402 - mae: 117.9614 - val_loss: 19178.4961 - val_mae: 116.7337\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20065.9941 - mae: 120.0851 - val_loss: 18509.7734 - val_mae: 115.8177\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18062.3105 - mae: 115.0376 - val_loss: 18306.8867 - val_mae: 115.7354\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16790.0430 - mae: 111.7368 - val_loss: 18328.1211 - val_mae: 116.1182\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17402.9531 - mae: 114.3622 - val_loss: 18367.2305 - val_mae: 116.4872\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16681.3418 - mae: 111.7516 - val_loss: 18364.5645 - val_mae: 116.6502\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16856.0879 - mae: 111.4802 - val_loss: 18418.0059 - val_mae: 116.9097\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16729.6680 - mae: 111.5761 - val_loss: 18389.4414 - val_mae: 116.7824\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17912.7246 - mae: 116.1410 - val_loss: 18428.5449 - val_mae: 116.9935\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16354.3818 - mae: 109.7907 - val_loss: 18390.9258 - val_mae: 116.8251\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17104.3672 - mae: 113.3826 - val_loss: 18420.5508 - val_mae: 116.9871\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16790.6270 - mae: 111.8337 - val_loss: 18415.9414 - val_mae: 116.9374\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18087.1543 - mae: 116.1021 - val_loss: 18417.7988 - val_mae: 117.0144\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17394.2031 - mae: 113.8205 - val_loss: 18386.1895 - val_mae: 116.7842\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16088.4912 - mae: 108.4576 - val_loss: 18397.7734 - val_mae: 116.9312\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17595.0742 - mae: 115.2591 - val_loss: 18376.3203 - val_mae: 116.8765\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16903.8809 - mae: 113.3736 - val_loss: 18391.0625 - val_mae: 116.8881\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16720.3457 - mae: 110.2689 - val_loss: 18378.4062 - val_mae: 116.8914\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17079.5938 - mae: 113.8655 - val_loss: 18367.1758 - val_mae: 116.9316\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17303.2910 - mae: 114.6688 - val_loss: 18388.1836 - val_mae: 116.9257\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18201.7363 - mae: 115.8803 - val_loss: 18336.7227 - val_mae: 116.8002\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18243.0371 - mae: 119.1634 - val_loss: 18348.9219 - val_mae: 116.8341\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17503.3438 - mae: 114.9995 - val_loss: 18342.9688 - val_mae: 116.8076\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16740.8438 - mae: 110.9730 - val_loss: 18318.3027 - val_mae: 116.7724\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16497.8203 - mae: 110.4569 - val_loss: 18357.4141 - val_mae: 116.9361\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17071.5781 - mae: 112.8377 - val_loss: 18280.1445 - val_mae: 116.6360\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16951.3262 - mae: 112.3435 - val_loss: 18293.5898 - val_mae: 116.6298\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16889.7891 - mae: 113.5687 - val_loss: 18293.5449 - val_mae: 116.7540\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17055.1992 - mae: 112.7789 - val_loss: 18330.5293 - val_mae: 116.8723\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16665.7910 - mae: 111.6197 - val_loss: 18310.4844 - val_mae: 116.8388\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16110.5791 - mae: 108.0247 - val_loss: 18286.9121 - val_mae: 116.7299\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17136.8105 - mae: 113.4870 - val_loss: 18293.9297 - val_mae: 116.7416\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16782.5332 - mae: 111.8963 - val_loss: 18320.8008 - val_mae: 116.8811\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16331.7510 - mae: 110.3882 - val_loss: 18288.7441 - val_mae: 116.7356\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18024.8418 - mae: 115.0808  \n",
            "Test Mean Absolute Error: 115.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONSNn5Oz1llh",
        "outputId": "773d4bc9-9086-4a83-b408-0f040f345af5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[295.8373 ],\n",
              "       [254.2767 ],\n",
              "       [257.19516],\n",
              "       [207.21716],\n",
              "       [348.5683 ],\n",
              "       [309.6844 ],\n",
              "       [321.36218],\n",
              "       [293.80988],\n",
              "       [297.5292 ],\n",
              "       [282.86682],\n",
              "       [240.38965],\n",
              "       [261.83533],\n",
              "       [283.1682 ],\n",
              "       [227.71286],\n",
              "       [306.8505 ],\n",
              "       [323.11462],\n",
              "       [260.5912 ],\n",
              "       [304.27356],\n",
              "       [306.9405 ],\n",
              "       [247.78056],\n",
              "       [271.83636],\n",
              "       [289.94977],\n",
              "       [286.17303],\n",
              "       [278.21747],\n",
              "       [250.79642],\n",
              "       [240.47559],\n",
              "       [256.9533 ],\n",
              "       [323.50037],\n",
              "       [324.53317],\n",
              "       [266.7083 ],\n",
              "       [229.17953],\n",
              "       [298.00476],\n",
              "       [295.06512],\n",
              "       [267.0001 ],\n",
              "       [318.86685],\n",
              "       [294.1551 ],\n",
              "       [211.55289],\n",
              "       [256.8682 ],\n",
              "       [288.78418],\n",
              "       [236.74672],\n",
              "       [250.92007],\n",
              "       [262.56354],\n",
              "       [253.09335],\n",
              "       [255.83827],\n",
              "       [272.23584],\n",
              "       [255.65227],\n",
              "       [262.5666 ],\n",
              "       [255.24883],\n",
              "       [299.66986],\n",
              "       [292.9663 ],\n",
              "       [219.03503],\n",
              "       [257.42096],\n",
              "       [262.02957],\n",
              "       [211.06331],\n",
              "       [321.5433 ],\n",
              "       [300.65836],\n",
              "       [253.56702],\n",
              "       [278.82678],\n",
              "       [263.5116 ],\n",
              "       [279.3893 ],\n",
              "       [258.7675 ],\n",
              "       [272.2069 ],\n",
              "       [282.36792],\n",
              "       [312.2779 ],\n",
              "       [312.16974],\n",
              "       [264.2603 ],\n",
              "       [311.57825],\n",
              "       [250.90504],\n",
              "       [247.72552],\n",
              "       [226.78091],\n",
              "       [313.65332],\n",
              "       [258.81326],\n",
              "       [278.87363],\n",
              "       [265.46198],\n",
              "       [264.66882],\n",
              "       [293.93918],\n",
              "       [229.68729],\n",
              "       [217.06302],\n",
              "       [277.65768],\n",
              "       [282.17938],\n",
              "       [239.33632],\n",
              "       [295.0864 ],\n",
              "       [252.37915],\n",
              "       [295.97192],\n",
              "       [251.7532 ],\n",
              "       [258.09207],\n",
              "       [299.81732],\n",
              "       [292.79083],\n",
              "       [215.93005],\n",
              "       [293.22092],\n",
              "       [331.6114 ],\n",
              "       [259.00507],\n",
              "       [291.96313],\n",
              "       [246.3153 ],\n",
              "       [231.71193],\n",
              "       [253.50131],\n",
              "       [265.9228 ],\n",
              "       [281.1306 ],\n",
              "       [200.83908],\n",
              "       [252.75969],\n",
              "       [276.44843],\n",
              "       [261.82257],\n",
              "       [273.37003],\n",
              "       [268.19458],\n",
              "       [216.11143],\n",
              "       [272.05154],\n",
              "       [341.05176],\n",
              "       [300.5677 ],\n",
              "       [286.23035],\n",
              "       [266.15033],\n",
              "       [343.88373],\n",
              "       [257.9654 ],\n",
              "       [308.7164 ],\n",
              "       [218.61642],\n",
              "       [268.89417],\n",
              "       [269.67816],\n",
              "       [239.04562],\n",
              "       [294.631  ],\n",
              "       [245.39851],\n",
              "       [337.77975],\n",
              "       [250.41263],\n",
              "       [276.80768],\n",
              "       [202.55998],\n",
              "       [250.80203],\n",
              "       [291.36807],\n",
              "       [238.02574],\n",
              "       [217.27881],\n",
              "       [280.56592],\n",
              "       [256.65225],\n",
              "       [279.13702],\n",
              "       [317.86957],\n",
              "       [270.62057],\n",
              "       [301.65247],\n",
              "       [282.2614 ],\n",
              "       [274.79352],\n",
              "       [281.19547],\n",
              "       [278.56738],\n",
              "       [266.8343 ],\n",
              "       [251.63611],\n",
              "       [283.09888],\n",
              "       [276.50916],\n",
              "       [309.05087],\n",
              "       [279.49042],\n",
              "       [248.77538],\n",
              "       [220.41719],\n",
              "       [245.52837],\n",
              "       [261.32343],\n",
              "       [293.96033],\n",
              "       [215.91672],\n",
              "       [291.3241 ],\n",
              "       [216.68636],\n",
              "       [266.65286],\n",
              "       [281.8246 ],\n",
              "       [295.39624],\n",
              "       [238.91904],\n",
              "       [251.05293],\n",
              "       [250.69542],\n",
              "       [235.1768 ],\n",
              "       [304.12112],\n",
              "       [296.54858],\n",
              "       [215.04584],\n",
              "       [262.34128],\n",
              "       [244.3959 ],\n",
              "       [262.80475],\n",
              "       [250.05396],\n",
              "       [301.43924],\n",
              "       [262.61334],\n",
              "       [292.3063 ],\n",
              "       [281.9251 ],\n",
              "       [238.8375 ],\n",
              "       [247.31496],\n",
              "       [219.32404],\n",
              "       [278.93146],\n",
              "       [271.6403 ],\n",
              "       [244.86655],\n",
              "       [224.21652],\n",
              "       [283.23663],\n",
              "       [259.17188],\n",
              "       [269.45114],\n",
              "       [257.11884],\n",
              "       [200.66019],\n",
              "       [249.42215],\n",
              "       [292.29196],\n",
              "       [252.12985],\n",
              "       [211.09424],\n",
              "       [229.92857],\n",
              "       [321.70825],\n",
              "       [266.08368],\n",
              "       [286.10596],\n",
              "       [264.7832 ],\n",
              "       [291.07385],\n",
              "       [287.9478 ],\n",
              "       [251.88672],\n",
              "       [261.40787],\n",
              "       [282.73236],\n",
              "       [282.79138],\n",
              "       [279.7079 ],\n",
              "       [252.9815 ],\n",
              "       [259.76016],\n",
              "       [300.05994]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(model,open('model.pkl','wb'))"
      ],
      "metadata": {
        "id": "H4aK79I51mYu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vr13EIGY16zj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}